{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ca0b774-51d4-4724-8dae-bdeec7b2448a",
   "metadata": {},
   "source": [
    "**Введение**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911522c2-769a-4635-aeea-a7f70ebf6f05",
   "metadata": {},
   "source": [
    "Подготовка данных является, на мой взгляд, сильно недооцененным этапом при разработке модели. Нет, важность этого момента подчеркивается повсеместно. Но я крайне редко встречал обоснование применения некоего метода к конкретным данным. \"Импутируем средним\", \"применим PCA\", \"найдем outliers по стандартному отклонению\". Я всё время задавался вопросом - а на каком основании? Этот вопрос поднимается крайне редно или не поднимается вобще, или вскользь. Best practicies, этого достаточно.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b41d1-3c24-4dc5-adb3-b8e1b50dd197",
   "metadata": {},
   "source": [
    "Мои поиски привели меня к Levels of mesurement. Приведу три иллюстрации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ab376",
   "metadata": {},
   "source": [
    "![title](img/dt_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac9017e-6104-418d-96db-9dfd6012bb06",
   "metadata": {},
   "source": [
    "![title](img/dt_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77fc174-b9fd-4ca0-800f-d3a2dd461000",
   "metadata": {},
   "source": [
    "![title](img/dt_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9d0bff",
   "metadata": {},
   "source": [
    "<a href=https://medium.com/@rndayala/data-levels-of-measurement-4af33d9ab51a>Источник.</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37493a80",
   "metadata": {},
   "source": [
    "Как оказалось, тип данных, с которым я имею дело принципиально важен. Не любой анализ или преобразование можно применять к любым данным.<br>\n",
    "Даже элементарное понимание дискретен предиктор или нет позволяет получить намного меньше шума при импутации KNN или MissingForest, просто округлив значения.<br>\n",
    "Имея мизерный опыт в ML я уже столкнулся в известном датасете Pima Indians с нулевыми значениями предикторов, которые являлись NaN по сути - теперь понятно почему.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25e169",
   "metadata": {},
   "source": [
    "Второй неутешительный момент - производительность.<br>\n",
    "Посмотрев в замочную скважину на обрезанный, но реальный датасет, я понял что sklearn и остальные библиотеки начального (если можно так выразиться) уровня для реальной работы подходят не всегда.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5522bc5",
   "metadata": {},
   "source": [
    "Предварительный анализ данных это однотипная и обязательная операция и естественной моей мыслью было неким образом автоматизировать этот процесс.<br>\n",
    "И если вопрос производительности можно решать при помощи Dask и JAX (и библиотек на его основе) хотя-бы на уровне полной утилизации ресурсов одной локальной машины. То с данными ситуация оказалась несколько сложней.<br>\n",
    "Оказалось, что вопрос определения с какими фичами в датасете я имею дело не тривиален. Датасеты всё больше, данных собирается больше, и за их конфеденциальностью следят всё сильнее. В том же Fraud Detection уже не спросишь что такое V277 и почему так много NaN. Насколько я понял это тенденция, а не частный случай.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a10e03e",
   "metadata": {},
   "source": [
    "На все выше написанное можно было-бы возразить - работает же, какие-то уровни, можно-нельзя. Все так делают и все работает, точность присутствует, места на kaggle имеют место быть и так далее.<br>\n",
    "Меня эти сомнения посещали. Но потом я задумался - где работает? На сгенерированных датасетах или датасетах собранных сорок лет назад, которые теперь используются для обучения на любом ноутбуке?<br> \n",
    "Нет, меня такая формулировка не устраивает. \n",
    "1. Не могу судить, может \"правильный\" подход будет в реальной жизни привозить +0,001 к точности модели, может забирать 10% - я проверю. \n",
    "2. Я считаю, что обрабатывая данные не задумываясь о основаниях мы привносим в модель непонятный inductive bias. И можем получить еще более непонятный hidden inductive bias от модели. \n",
    "3. ИМХО, Science в слове DataScience как-бы обязывает хотя-бы попытаться понять что делаешь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2522c595",
   "metadata": {},
   "source": [
    "**Предварительная постановка задачи**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bde15ee",
   "metadata": {},
   "source": [
    "Стараясь трезво оценивать свои возможности, я не буду самонадеянно формулировать задачу \"Буду делать AutoML\".<br>\n",
    "На первой итерации я хотел-бы иметь утилиту, которая выполняла следующие функции:\n",
    "1. Избавляла от рутинных, однотипных операций по предварительному анализу.\n",
    "2. Оптимизировала производительность. Желательно с возможностью подключения к GCP, Amazon кластерам \"из коробки\".\n",
    "3. Проводила предварительный элементарный анализ фич. Дискретность, последовательность, отношение уникальных значений к общему их числу, разряженность.\n",
    "4. Нужно попытаться хотя-бы на уровне интуиции сформулировать правила разделения данных. Хотя-бы определение категорий."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4929ce",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
